{"Shader":{"ver":"0.1","info":{"id":"XtsSzH","date":"1434504903","viewed":1483,"name":"Correct Picture Blurring","username":"iq","description":"The correct way to blur\/downsample <strong>PICTURES<\/strong> (as opposed to images in general) is to remove the gamma correction of the picture <strong>before<\/strong> the linear transform and apply it again <strong>after<\/strong> the transform. Otherwise brightness is lost.","likes":17,"published":3,"flags":0,"tags":["2d","blur","gamma","degamma"],"hasliked":0},"renderpass":[{"inputs":[{"id":5,"src":"\/presets\/tex04.jpg","ctype":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"false","srgb":"false","internal":"byte"}}],"outputs":[{"channel":"0"}],"code":"\/\/ Created by inigo quilez - iq\/2015\n\/\/ License Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.\n\n\n\/\/ The correct way to do blurring, convolution or downsampling for PICTURES is to \n\/\/ apply the gamma\/degamma before the linear operations. Of course most people do\n\/\/ not apply the pow() for performanc reasons, but that is wrong:\n\/\/\n\/\/ Notice how the image gets darker when the averaging is done with the raw pixel\n\/\/ values. However, when degammaing the colors prior to accumulation and applying\n\/\/ gamma after normalization, the image has no lose in brightness.\n\/\/\n\/\/ Basically if x is your input picture, T your blurring\/convolution\/filter and y \n\/\/ you resulting image, instead of doing\n\/\/\n\/\/ y = T( x )\n\/\/ \n\/\/ you should do \n\/\/\n\/\/ y = G( T(G^-1(x)) )\n\/\/\n\/\/ where G(x) is the expected gamma function (usually G(x) = x^2.2)\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    \n    \/\/ ------------------------------------------------------------\n    \n    \/\/ image downsampling\/blurring\/averaging\n    vec3 totWrong = vec3(0.0);\n    vec3 totCorrect = vec3(0.0);\n    \n    for( int j=0; j<9; j++ )\n    for( int i=0; i<9; i++ )\n    {\n        vec2 st = ( fragCoord.xy + vec2(float(i-4),float(j-4)) ) \/iChannelResolution[0].xy;\n        vec3 co = texture2D( iChannel0, vec2(st.x,1.0-st.y) ).xyz;\n        \n        totWrong   += co;                \/\/ what most people do (incorrect)\n        totCorrect += pow(co,vec3(2.2)); \/\/ what you should do\n    }\n    \n    vec3 colWrong   = totWrong \/ 81.0;                    \/\/ what most people do (incorrect)\n    vec3 colCorrect = pow(totCorrect\/81.0,vec3(1.0\/2.2)); \/\/ what you should do\n\n\n    \/\/ ------------------------------------------------------------\n\n    \/\/ reference\/original image\n    vec2 st = fragCoord.xy \/ iChannelResolution[0].xy;\n    vec3 colReference = texture2D( iChannel0, vec2(st.x,1.0-st.y) ).xyz;\n    \n    \/\/ final image\n    vec2 q = fragCoord.xy \/ iResolution.xy;\n    float th = 0.1 + 0.8*smoothstep(-0.1,0.1,sin(0.25*6.2831*iGlobalTime) );\n    vec3 col = mix( (q.y>th)?colWrong:colCorrect, colReference, smoothstep( -0.1, 0.1, sin(6.2831*iGlobalTime) ) );\n    col *= smoothstep( 0.005, 0.006, abs(q.y-th) );\n        \n\tfragColor = vec4( col, 1.0 );\n}","name":"","description":"","type":"image"}]}}