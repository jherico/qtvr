{"Shader":{"ver":"0.1","info":{"id":"XsG3z1","date":"1453385637","viewed":294,"name":"Reaction Diffusion - 2 Pass","username":"Shane","description":"2 pass reaction diffusion - based on Flexi's \"Expansive Reaction-Diffusion\" example.","likes":34,"published":3,"flags":32,"tags":["diffusion","gaussian","laplacian","reaction","highlighting"],"hasliked":0},"renderpass":[{"inputs":[{"id":257,"src":"\/presets\/previz\/buffer00.png","ctype":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"}}],"outputs":[{"channel":"0"}],"code":"\/*\n\tReaction Diffusion - 2 Pass\n\t---------------------------\n\n\tSimple 2 pass reaction-diffusion, based off of \"Flexi's\" reaction-diffusion examples.\n\tIt takes about ten seconds to reach an equilibrium of sorts, and in the order of a \n\tminute longer for the colors to really settle in.\n\n\tI'm really thankful for the examples Flexi has been putting up lately. From what I \n\tunderstand, he's used to showing his work to a lot more people on much bigger screens,\n\tso his code's pretty reliable. Reaction-diffusion examples are temperamental. Change \n\tone figure by a minute fraction, and your image can disappear. That's why it was really \n\tnice to have a working example to refer to. \n\t\n    Anyway, I've done things a little differently, but in essense, this is just a rehash \n\tof Flexi's \"Expansive Reaction-Diffusion\" example. I've stripped this one down to the \n\tbasics, so hopefully, it'll be a little easier to take in than the multitab version.\n\n\tThere are no outside textures, and everything is stored in the A-Buffer. I was \n\toriginally going to simplify things even more and do a plain old, greyscale version, \n\tbut figured I'd better at least try to pretty it up, so I added color and some very \n\tbasic highlighting. I'll put up a more sophisticated version at a later date.\n\n\tBy the way, for anyone who doesn't want to be weighed down with extras, I've provided \n\ta simpler \"Image\" tab version below.\n\n\tOne more thing. Even though I consider it conceptually impossible, it wouldn't surprise\n\tme at all if someone, like Fabrice, produces a single pass, two tweet version. :)\n\n\tBased on:\n\t\n\t\/\/ Gorgeous, more sophisticated example:\n\tExpansive Reaction-Diffusion - Flexi\n\thttps:\/\/www.shadertoy.com\/view\/4dcGW2\n\n\t\/\/ A different kind of diffusion example. Really cool.\n\tGray-Scott diffusion - knighty\n\thttps:\/\/www.shadertoy.com\/view\/MdVGRh\n\n\t\n*\/\n\n\/*\n\/\/ Ultra simple version, minus the window dressing.\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n    fragColor = 1. - texture2D(iChannel0, fragCoord\/iResolution.xy).wyyw;\n\n}\n*\/\n\nvoid mainImage(out vec4 fragColor, in vec2 fragCoord){\n\n    \n    \/\/ The screen coordinates.\n    vec2 uv = fragCoord\/iResolution.xy;\n    \n    \/\/ Read in the blurred pixel value. There's no rule that says you can't read in the\n    \/\/ value in the \"X\" channel, but blurred stuff is easier to bump, that's all.\n    float c = 1. - texture2D(iChannel0, uv).y; \n    \/\/ Reading in the same at a slightly offsetted position. The difference between\n    \/\/ \"c2\" and \"c\" is used to provide the highlighting.\n    float c2 = 1. - texture2D(iChannel0, uv + .5\/iResolution.xy).y;\n    \n\n    \/\/ Color the pixel by mixing two colors in a sinusoidal kind of pattern.\n    \/\/\n    float pattern = -cos(uv.x*0.75*3.14159-0.9)*cos(uv.y*1.5*3.14159-0.75)*0.5 + 0.5;\n    \/\/\n    \/\/ Blue and gold, for an abstract sky over a... wheat field look. Very artsy. :)\n    vec3 col = vec3(c*1.5, pow(c, 2.25), pow(c, 6.));\n    col = mix(col, col.zyx, clamp(pattern-.2, 0., 1.) );\n    \n    \/\/ Extra color variations.\n    \/\/vec3 col = mix(vec3(c*1.2, pow(c, 8.), pow(c, 2.)), vec3(c*1.3, pow(c, 2.), pow(c, 10.)), pattern );\n\t\/\/vec3 col = mix(vec3(c*1.3, c*c, pow(c, 10.)), vec3(c*c*c, c*sqrt(c), c), pattern );\n    \n    \/\/ Adding the highlighting. Not as nice as bump mapping, but still pretty effective.\n    col += vec3(.6, .85, 1.)*max(c2*c2 - c*c, 0.)*12.;\n\n    \/\/ Apply a vignette and increase the brightness for that fake spotlight effect.\n    col *= pow( 16.0*uv.x*uv.y*(1.0-uv.x)*(1.0-uv.y) , .125)*1.15;\n    \n    \/\/ Fade in for the first few seconds.\n    col *= smoothstep(0., 1., iGlobalTime\/2.);\n\n    \/\/ Done.\n    fragColor = vec4(min(col, 1.), 1.); \n\n    \n}\n\n","name":"","description":"","type":"image"},{"inputs":[{"id":257,"src":"\/presets\/previz\/buffer00.png","ctype":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"}}],"outputs":[{"channel":"0"}],"code":"\/\/ Reaction-diffusion pass.\n\/\/\n\/\/ If want a really short, non technical explanation, here goes: First, you sprinkle the buffer \n\/\/ with some initial noise on the first few frames (Sometimes, the first frame gets skipped, so \n\/\/ you do a few more).\n\/\/\n\/\/ During the buffer loop pass, determine the reaction diffusion value using a combination of the \n\/\/ value stored in the buffer's \"X\" channel, and a the blurred value - stored in the \"Y\" channel \n\/\/ (You can see how that's done in the code below). Blur the value from the \"X\" channel (the old \n\/\/ reaction diffusion value) and store it in \"Y\", then store the new (reaction diffusion) value \n\/\/ in \"X.\" Display either the \"X\" value  or \"Y\" buffer value in the \"Image\" tab, add some window \n\/\/ dressing, then repeat the process. Simple... Slightly confusing when I try to explain it, but \n\/\/ trust me, it's simple. :)\n\/\/\n\/\/ Anyway, for a more sophisticated explanation, here are a couple of references below:\n\/\/\n\/\/ Reaction-Diffusion by the Gray-Scott Model - http:\/\/www.karlsims.com\/rd.html\n\/\/ Reaction-Diffusion Tutorial - http:\/\/www.karlsims.com\/rd.html\n\n\/\/ Cheap vec3 to vec3 hash. Works well enough, but there are other ways.\nvec3 hash33(in vec2 p){ \n    float n = sin(dot(p, vec2(41, 289)));    \n    return fract(vec3(2097152, 262144, 32768)*n); \n}\n\n\/\/ Serves no other purpose than to save having to write this out all the time. I could write a \n\/\/ \"define,\" but I'm pretty sure this'll be inlined.\nvec4 tx(in vec2 p){ return texture2D(iChannel0, p); }\n\n\/\/ Weighted blur function. Pretty standard.\nfloat blur(in vec2 p){\n    \n    \/\/ Used to move to adjoining pixels. - uv + vec2(-1, 1)*px, uv + vec2(1, 0)*px, etc.\n    vec3 e = vec3(1, 0, -1);\n    vec2 px = 1.\/iResolution.xy;\n    \n    \/\/ Weighted 3x3 blur, or a cheap and nasty Gaussian blur approximation.\n\tfloat res = 0.0;\n    \/\/ Four corners. Those receive the least weight.\n\tres += tx(p + e.xx*px ).x + tx(p + e.xz*px ).x + tx(p + e.zx*px ).x + tx(p + e.zz*px ).x;\n    \/\/ Four sides, which are given a little more weight.\n    res += (tx(p + e.xy*px ).x + tx(p + e.yx*px ).x + tx(p + e.yz*px ).x + tx(p + e.zy*px ).x)*2.;\n\t\/\/ The center pixel, which we're giving the most weight to, as you'd expect.\n\tres += tx(p + e.yy*px ).x*4.;\n    \/\/ Normalizing.\n    return res\/16.;     \n    \n}\n\n\/\/ The reaction diffusion loop.\n\/\/ \nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ){\n\n    \n\tvec2 uv = fragCoord\/iResolution.xy; \/\/ Screen coordinates. Range: [0, 1]\n    vec2 pw = 1.\/iResolution.xy; \/\/ Relative pixel width. Used for neighboring pixels, etc.\n    \n    \n    \/\/ The blurred pixel. This is the result that's used in the \"Image\" tab. It's also reused\n    \/\/ in the next frame in the reaction diffusion process above.\n\tfloat avgReactDiff = blur(uv);\n\n    \n\t\/\/ The noise value. Because the result is blurred, we can get away with plain old static noise.\n    \/\/ However, smooth noise, and various kinds of noise textures will work, too.\n    vec3 noise = hash33(uv + vec2(53, 43)*iGlobalTime)*.6 + .2;\n\n    \/\/ Used to move to adjoining pixels. - uv + vec2(-1, 1)*px, uv + vec2(1, 0)*px, etc.\n    vec3 e = vec3(1, 0, -1);\n    \n    \/\/ Gradient epsilon value. The \"1.5\" figure was trial and error, but was based on the 3x3 blur radius.\n    vec2 pwr = pw*1.5; \n    \n    \/\/ Use the blurred pixels (stored in the Y-Channel) to obtain the gradient. I haven't put too much \n    \/\/ thought into this, but the gradient of a pixel on a blurred pixel grid (average neighbors), would \n    \/\/ be analogous to a Laplacian operator on a 2D discreet grid. Laplacians tend to be used to describe \n    \/\/ chemical flow, so... Sounds good, anyway. :)\n    \/\/\n    \/\/ Seriously, though, take a look at the formula for the reacion-diffusion process, and you'll see\n    \/\/ that the following few lines are simply putting it into effect.\n    \n    \/\/ Gradient of the blurred pixels from the previous frame.\n\tvec2 lap = vec2(tx(uv + e.xy*pwr).y - tx(uv - e.xy*pwr).y, tx(uv + e.yx*pwr).y - tx(uv - e.yx*pwr).y);\/\/\n    \n    \/\/ Add some diffusive expansion, scaled down to the order of a pixel width.\n    uv = uv + lap*pw*3.0; \n    \n    \/\/ Stochastic decay. Ie: A differention equation, influence by noise.\n    \/\/ You need the decay, otherwise things would keep increasing, which in this case means a white screen.\n    float newReactDiff = tx(uv).x + (noise.z - 0.5)*0.0025 - 0.002; \n    \n    \/\/ Reaction-diffusion.\n\tnewReactDiff += dot(tx(uv + (noise.xy-0.5)*pw).xy, vec2(1, -1))*0.145; \n\n    \n    \/\/ Storing the reaction diffusion value in the X channel, and avgReactDiff (the blurred pixel value) \n    \/\/ in the Y channel. However, for the first few frames, we add some noise. Normally, one frame would \n    \/\/ be enough, but for some weird reason, it doesn't always get stored on the very first frame.\n    if(iFrame>9) fragColor.xy = clamp(vec2(newReactDiff, avgReactDiff\/.98), 0., 1.);\/\/\/.98\n    else fragColor = vec4(noise, 1.);\n    \n}","name":"","description":"","type":"buffer"}]}}